 Renaissance Text Synthesizer (with Degradation)

TL;DR
This repo contains a mid-scale generative model (U-Net + DDIM) for synthesizing Renaissance-style Spanish printed text, complete with historical imperfections: ink bleed, smudging, and fading. The goal: generate convincing degraded text images from 17th-century Spanish content using modern diffusion techniques.
ğŸ§  Model
â€¢ Architecture: U-Net (encoder-decoder with skip connections)
â€¢ Diffusion Framework: DDIM (fast sampling, fewer steps)
â€¢ Training Objective: Learn to reconstruct degraded Renaissance-style text from noise
ğŸ› ï¸ Pipeline Overview 
[Historical Spanish Text]
        â†“
[Font Rendering (Renaissance-style)]
        â†“
[Training Data: Clean â†” Degraded]
        â†“
[U-Net + DDIM Training]
        â†“
[Sampled Degraded Images]
Directory structure
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ clean/        # Rendered clean text images (no degradation)
â”‚   â””â”€â”€ degraded/     # Text images with ink bleed, smudging, fading
â”‚
â”œâ”€â”€ outputs/          # Final generated samples and evaluation metrics
â”‚
â”œâ”€â”€ scripts/          # Training, sampling, preprocessing scripts
â”‚
â”œâ”€â”€ utils/            # Helper functions and shared utilities
â”‚
â”œâ”€â”€ README.md         # Project documentation
â””â”€â”€ requirements.txt  # Dependency list
ğŸ“ˆ Evaluation
Realism isn't easy to quantifyâ€”but we tried:
â€¢ LPIPS: Perceptual similarity, favors realism over pixel accuracy
â€¢ SSIM: Structural fidelity, useful for edge/text clarity
â€¢ (Optional) Human Rating
ğŸ–¼ï¸ Results
Generated outputs convincingly mimic:
â€¢ Fuzzy ink in tight curves
â€¢ Gradient-like fading toward margins
â€¢ Inconsistent smudge directionality
ğŸ” Why DDIM?
I tried GANs. Required a lot of data to train and very unstable. I wanted control, repeatability, and graceful degradationâ€”not mode collapse. DDIM gives us:
â€¢ Smooth interpolation
â€¢ Faster sampling
â€¢ More predictable noise schedules
ğŸ“š Dataset
I used a curated sample of 17th-century Spanish text, formatted via:
â€¢ Renaissance.ttf-style fonts
â€¢ Custom scripts for rendering 
â€¢ Clean/degraded pair generation with seed control
ğŸš§ Limitations & Next Steps
â€¢ No multi-column formatting yet
â€¢ Augmentations could benefit from learned degradation (e.g. adversarial ink smudge)
â€¢ Would like to compare against Stable Diffusion + LoRA fine-tuning
ğŸ§¾ References
â€¢ DDIM: Denoising Diffusion Implicit Models (https://arxiv.org/abs/2010.02502)
â€¢ U-Net: Convolutional Networks for Biomedical Image Segmentation (https://arxiv.org/abs/1505.04597)

